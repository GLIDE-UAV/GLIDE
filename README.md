# GLIDE

This project is the implementation of [GLIDE Scheme]().

## **Description**
GLIDE addresses the challenge of controlling the movement of a fleet of UAVs by using Multi-Agent Deep Reinforcement Learning (MARL). A continuous-time based Proximal Policy Optimization (PPO) algorithm for multi-aGent Learning In Dynamic Environments called GLIDE is implemented. The action control in GLIDE can be centralized and decentralized based on the two algorithms called Centralized-GLIDE(C-GLIDE), and Decentralized-GLIDE(D-GLIDE). UAV_sim is the simulator code for our implementation. The C-GLIDE and the D-GLIDE folders have the GLIDE implmentation using UAV_SIM.

<!-- ## Citing the Project

To cite this repository in publications:

```
@misc{glide,
  author = {},
  title = {GLIDE},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.itap.purdue.edu/Clan-labs/GLIDE.git}},
}
``` -->

# Installation and Usage
Download or clone this repository.

First go to UAV_sim folder and follow the instructions to set up the environment. 

Next, go to the C-GLIDE or D_GLIDE folder and follow the steps to run the code..
<!-- The plots folder is to generate plots from the experimental data. -->

<!-- ## Dependencies -->



<!-- ## Steps to run GLIDE -->



 

# License
[MIT LICENSE](LICENSE)

